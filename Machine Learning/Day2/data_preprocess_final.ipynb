{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "144e4fc6-771c-418d-84ff-26e73ec74cbf",
   "metadata": {},
   "source": [
    "## Code and methods for data preprocessing.\n",
    "\n",
    "Topics:\n",
    "\n",
    "1. Finding and removing outliers in the data.\n",
    "2. Finding and removing gaps in the data.\n",
    "3. Resampling the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1283ff52-000a-4fa4-b45d-b4620456d13a",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Important necessary libraries\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m List, Tuple\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmpl\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mplt\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pandas'"
     ]
    }
   ],
   "source": [
    "# Important necessary libraries\n",
    "\n",
    "from typing import List, Tuple\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import datetime\n",
    "from scipy import signal\n",
    "import warnings\n",
    "\n",
    "#ignore warnings for the notebook\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "10f8acbd-acdc-4d6d-9553-07e3c904d155",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of         Unnamed: 0                 DATE  gauge_height\n",
       "0                0  2008-01-01 00:00:00          5.76\n",
       "1                1  2008-01-01 00:15:00          5.75\n",
       "2                2  2008-01-01 00:30:00          5.73\n",
       "3                3  2008-01-01 00:45:00          5.71\n",
       "4                4  2008-01-01 01:00:00          5.69\n",
       "...            ...                  ...           ...\n",
       "571181      571181  2024-05-29 07:15:00          6.36\n",
       "571182      571182  2024-05-29 07:30:00          6.36\n",
       "571183      571183  2024-05-29 07:45:00          6.35\n",
       "571184      571184  2024-05-29 08:15:00          6.35\n",
       "571185      571185  2024-05-29 08:30:00          6.34\n",
       "\n",
       "[571186 rows x 3 columns]>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read data as a dataframe\n",
    "\n",
    "df = pd.read_csv('02336490_raw_data_manual.csv')\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a855c399-9057-4539-a22d-6d73a4b22446",
   "metadata": {},
   "source": [
    "## Finding Errors in the Data\n",
    "\n",
    "In some cases, there may be errors in the data you obtained.\n",
    "Sources of errors can include data entry mistakes, anomalies due to faulty sensors, etc.\n",
    "\n",
    "In our case, we only selected data with an 'A' approval mark, so there is a low chance of finding any errors. Nevertheless, we will review how to identify errors if they exist.\n",
    "\n",
    "We can use the `describe()` method to view basic statistics such as minimum value, maximum value, median, and the 1st and 3rd quartiles. Generally, errors have values that are either extremely high, extremely low, or negative.  \n",
    "These can be identified using this method.\n",
    "\n",
    "**If errors are found in the data, we simply remove them and then continue with the rest of the preprocessing methods.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "231f39b1-4194-4b98-acf0-244ff4f0093c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>gauge_height</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>571186.000000</td>\n",
       "      <td>571186.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>285592.500000</td>\n",
       "      <td>6.574300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>164887.339766</td>\n",
       "      <td>2.980596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.790000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>142796.250000</td>\n",
       "      <td>4.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>285592.500000</td>\n",
       "      <td>5.480000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>428388.750000</td>\n",
       "      <td>7.920000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>571185.000000</td>\n",
       "      <td>27.860000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Unnamed: 0   gauge_height\n",
       "count  571186.000000  571186.000000\n",
       "mean   285592.500000       6.574300\n",
       "std    164887.339766       2.980596\n",
       "min         0.000000       2.790000\n",
       "25%    142796.250000       4.300000\n",
       "50%    285592.500000       5.480000\n",
       "75%    428388.750000       7.920000\n",
       "max    571185.000000      27.860000"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64aaa2f5-fbb9-4925-8676-070006b2efa7",
   "metadata": {},
   "source": [
    "- We don’t see any anomalous results in the statistics above, which suggests there are no notable errors.\n",
    "- However, the maximum value is significantly greater than the mean and isn’t captured within the standard deviation range.\n",
    "- Let’s check how many values are greater than 20."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d2f723f0-e504-4f68-a542-15f1065c3d16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(1665)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(df['gauge_height'] > 20.0).sum()\n",
    "\n",
    "## 1665 is a lot of values. We conclude that there's no error in the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c373a06-3777-44cb-b8ad-97c15bfe8043",
   "metadata": {},
   "source": [
    "## Finding Gaps in the Data\n",
    "\n",
    "Generally, two types of gaps can be found in time series data:\n",
    "\n",
    "1. Since hourly data is recorded at 15-minute intervals, there is a chance that an entire row might be missing, resulting in gaps in the time sequence itself.\n",
    "2. The second type occurs when the timestamp is present, but the gauge height is missing.\n",
    "\n",
    "We need to address the first type of gap and then proceed to the second.\n",
    "\n",
    "The following method will print all the time gaps in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "fb972af3-ae0a-4264-94d6-507249b79e82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing first 20 gaps...\n",
      "\n",
      "Gap found between 2008-03-09 01:45:00 and 2008-03-09 03:00:00: Gap: 0 days 01:15:00\n",
      "Gap found between 2008-03-14 08:00:00 and 2008-03-14 09:00:00: Gap: 0 days 01:00:00\n",
      "Gap found between 2008-03-20 19:15:00 and 2008-03-20 20:30:00: Gap: 0 days 01:15:00\n",
      "Gap found between 2008-03-22 07:00:00 and 2008-03-22 07:45:00: Gap: 0 days 00:45:00\n",
      "Gap found between 2008-03-23 07:00:00 and 2008-03-23 07:45:00: Gap: 0 days 00:45:00\n",
      "Gap found between 2008-03-24 03:45:00 and 2008-03-24 04:15:00: Gap: 0 days 00:30:00\n",
      "Gap found between 2008-03-31 07:00:00 and 2008-03-31 07:30:00: Gap: 0 days 00:30:00\n",
      "Gap found between 2008-04-01 16:00:00 and 2008-04-01 17:15:00: Gap: 0 days 01:15:00\n",
      "Gap found between 2008-04-03 07:15:00 and 2008-04-03 07:45:00: Gap: 0 days 00:30:00\n",
      "Gap found between 2008-04-03 08:15:00 and 2008-04-03 08:45:00: Gap: 0 days 00:30:00\n",
      "Gap found between 2008-04-03 18:30:00 and 2008-04-03 19:00:00: Gap: 0 days 00:30:00\n",
      "Gap found between 2008-04-04 07:00:00 and 2008-04-04 08:00:00: Gap: 0 days 01:00:00\n",
      "Gap found between 2008-04-11 08:30:00 and 2008-04-11 09:15:00: Gap: 0 days 00:45:00\n",
      "Gap found between 2008-04-16 06:15:00 and 2008-04-16 06:45:00: Gap: 0 days 00:30:00\n",
      "Gap found between 2008-04-17 09:15:00 and 2008-04-17 09:45:00: Gap: 0 days 00:30:00\n",
      "Gap found between 2008-04-27 08:30:00 and 2008-04-27 09:15:00: Gap: 0 days 00:45:00\n",
      "Gap found between 2008-04-28 02:30:00 and 2008-04-28 03:00:00: Gap: 0 days 00:30:00\n",
      "Gap found between 2008-04-28 04:30:00 and 2008-04-28 05:00:00: Gap: 0 days 00:30:00\n",
      "Gap found between 2008-04-30 00:45:00 and 2008-05-01 01:00:00: Gap: 1 days 00:15:00\n",
      "Gap found between 2008-05-01 01:15:00 and 2008-05-01 01:45:00: Gap: 0 days 00:30:00\n",
      "\n",
      "Total number of gaps: 484\n",
      "Max gap: 5 days 00:15:00\n",
      "Total gap: 49 days 05:30:00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(Timedelta('5 days 00:15:00'), Timedelta('49 days 05:30:00'))"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def find_missing_dates(df: pd.DataFrame, date_col: str = 'DATE', \n",
    "                       threshold: datetime.timedelta = datetime.timedelta(minutes=15)) -> Tuple[datetime.timedelta, datetime.timedelta]:\n",
    "    \"\"\"\n",
    "    Find gaps in the date column of a DataFrame.\n",
    "    \n",
    "    Args:\n",
    "    df (pd.DataFrame): Input DataFrame.\n",
    "    date_col (str): Name of the date column.\n",
    "    threshold (datetime.timedelta): Threshold for considering a gap.\n",
    "    \n",
    "    Returns:\n",
    "    Tuple[datetime.timedelta, datetime.timedelta]: Maximum gap and total gap.\n",
    "    \"\"\"\n",
    "\n",
    "    # convert the DATE column to datetime datatype - originally string\n",
    "    df[date_col] = pd.to_datetime(df[date_col])\n",
    "\n",
    "    # sort values in ascending order by DATE column\n",
    "    df = df.sort_values(by=date_col)\n",
    "    \n",
    "    prev = df[date_col].iloc[0]\n",
    "    \n",
    "    total_gap = datetime.timedelta(minutes=0)\n",
    "    max_diff = threshold\n",
    "\n",
    "    print_gaps = 20\n",
    "    total_gaps = 0\n",
    "\n",
    "    print(f'Printing first {print_gaps} gaps...\\n')\n",
    "    for d in df[date_col].iloc[1:]:\n",
    "        diff = d - prev\n",
    "        if diff > max_diff:\n",
    "            max_diff = diff\n",
    "        if diff > threshold:\n",
    "            total_gap += diff\n",
    "            if print_gaps > 0:\n",
    "                print(f\"Gap found between {prev} and {d}: Gap: {diff}\")\n",
    "            print_gaps -= 1\n",
    "            total_gaps += 1\n",
    "        prev = d\n",
    "\n",
    "    print(f'\\nTotal number of gaps: {total_gaps}')\n",
    "    print(f'Max gap: {max_diff}')\n",
    "    print(f'Total gap: {total_gap}')\n",
    "    return max_diff, total_gap\n",
    "\n",
    "\n",
    "find_missing_dates(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6f308c1-8802-4be8-863f-775d746a2550",
   "metadata": {},
   "source": [
    "## Filling Missing Dates\n",
    "\n",
    "This process involves identifying the minimum and maximum dates in the dataset, then generating a complete datetime range at the specified frequency within that interval.  \n",
    "A new column is created for each timestamp in this range, and corresponding values from the original data are assigned to matching timestamps.\n",
    "\n",
    "Datetimes with no matching data will remain as empty entries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3925e82e-fb36-4543-9e1d-54f1963b1a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def fill_missing_dates(df: pd.DataFrame, freq = '15min' ) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Process USGS data: set index, fill missing values, and interpolate.\n",
    "    \n",
    "    Args:\n",
    "    df (pd.DataFrame): Input DataFrame with USGS data.\n",
    "    \n",
    "    Returns:\n",
    "    pd.DataFrame: Processed DataFrame.\n",
    "    \"\"\"\n",
    "    df.set_index('DATE', inplace=True)\n",
    "    df.sort_index(inplace=True)\n",
    "    df = df.groupby(df.index).mean()\n",
    "\n",
    "    full_range = pd.date_range(start=df.index.min(), end=df.index.max(), freq=freq)\n",
    "    df_filled = df.reindex(full_range)\n",
    "    \n",
    "    df_filled.reset_index(inplace=True)\n",
    "    df_filled.rename(columns={'index': 'DATE'}, inplace=True)\n",
    "    return df_filled\n",
    "\n",
    "df = fill_missing_dates(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13e899d5-eb85-4be9-bb49-d15b7052302b",
   "metadata": {},
   "source": [
    "## Missing Values\n",
    "\n",
    "In this section, we will discuss methods to fill missing values.\n",
    "\n",
    "First, let’s calculate the percentage of missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "12dda7e5-18ca-43c8-bbb4-50d807339018",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of missing values: 0.7372736863510514 %\n"
     ]
    }
   ],
   "source": [
    "missing_count = df['gauge_height'].isnull().sum()\n",
    "print(f'Percentage of missing values: {missing_count / len(df) * 100} %')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da1bfda1-f127-46dc-add5-472104c1fa25",
   "metadata": {},
   "source": [
    "Usually, less than 5% missing values is acceptable in a dataset.  \n",
    "In our case, it’s less than 1%, which is within an acceptable range.  \n",
    "The size of gaps also matters, as larger gaps are generally less favorable.\n",
    "\n",
    "**Let’s examine the size of gaps in our data.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1679cbda-ba24-46d6-8ead-12618ea51741",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 15 gaps: [480, 480, 384, 384, 288, 192, 192, 192, 192, 142, 96, 96, 96, 96, 96]\n",
      "all gaps:  [480, 480, 384, 384, 288, 192, 192, 192, 192, 142, 96, 96, 96, 96, 96, 46, 7, 7, 6, 6, 6, 5, 5, 5, 5, 5, 5, 5, 5, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "gap_sizes  = []\n",
    "gap_size = 0\n",
    "for val in df['gauge_height']:\n",
    "    if math.isnan(val):\n",
    "        gap_size += 1\n",
    "    else:\n",
    "        if gap_size > 0:\n",
    "            gap_sizes.append(gap_size)\n",
    "            gap_size = 0\n",
    "\n",
    "# sort in descending order\n",
    "sorted_gaps = sorted(gap_sizes, reverse=True)\n",
    "print(f'Top 15 gaps: {sorted_gaps[:15]}')\n",
    "print('all gaps: ', sorted_gaps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "061464ee-5127-4ac2-bbc7-c0cbda4d9623",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "We can see that the maximum gap is 480 entries, which translates to \\( 480/4 = 120 \\) hours, or 5 days. This is a large gap.  \n",
    "Regardless of the filling method used, it’s unlikely to perform better than simple linear interpolation in this case.  \n",
    "One option, when using machine learning models, is to load data in a way that skips these large gap periods.\n",
    "\n",
    "For our case, however, we’ll proceed with linear interpolation since the percentage of gaps is very low relative to the overall data size. Thus, any data errors introduced will have a negligible impact on the model.\n",
    "\n",
    "If you encounter many small gaps in your data, you could use techniques like the Kalman filter or other autoregressive methods to estimate the gaps more accurately.\n",
    "\n",
    "Let’s use linear interpolation to fill in the gaps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3769900a-7034-4323-821d-ec71cfc3f0ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_missing_values(data: pd.DataFrame, method='linear') -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Process data: interpolate missing values with linear interpolation.\n",
    "    \n",
    "    Args:\n",
    "    data (pd.DataFrame): Input DataFrame with data and 'DATE' column, which will be used as index.\n",
    "    \n",
    "    Returns:\n",
    "    pd.DataFrame: Processed DataFrame.\n",
    "    \"\"\"\n",
    "    data.set_index('DATE', inplace=True)\n",
    "    data.sort_index(inplace=True)\n",
    "    data = data.groupby(data.index).mean()\n",
    "    \n",
    "    for col in data.columns:\n",
    "        data[col] = data[col].interpolate(method = method)\n",
    "\n",
    "    data.reset_index(inplace=True)\n",
    "    data.rename(columns={'index': 'DATE'}, inplace=True)\n",
    "    return data\n",
    "\n",
    "filled_df = fill_missing_values(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbfb1201-e8e1-4797-ae02-9dc0b8fef78e",
   "metadata": {},
   "source": [
    "**How does this affect the statistics? Let's see.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ed9ad460-d9b3-4c25-a8db-0a044bb43946",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before filling gaps\n",
      " count    571121.000000\n",
      "mean          6.574456\n",
      "std           2.980629\n",
      "min           2.790000\n",
      "25%           4.300000\n",
      "50%           5.480000\n",
      "75%           7.920000\n",
      "max          27.860000\n",
      "Name: gauge_height, dtype: float64\n",
      "\n",
      "\n",
      "After filling gaps\n",
      " count    575363.000000\n",
      "mean          6.573636\n",
      "std           2.978890\n",
      "min           2.790000\n",
      "25%           4.310000\n",
      "50%           5.480000\n",
      "75%           7.920000\n",
      "max          27.860000\n",
      "Name: gauge_height, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print('Before filling gaps\\n', df['gauge_height'].describe())\n",
    "print('\\n\\nAfter filling gaps\\n', filled_df['gauge_height'].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07008556-8d61-466b-80c0-9daf567ada58",
   "metadata": {},
   "source": [
    "- We can see that there’s very little change in the basic statistics.\n",
    "\n",
    "## Resampling Data\n",
    "\n",
    "- The last step we need to address is data resampling.\n",
    "- We are going to incorporate meteorological data, which is collected at 1-hour intervals.\n",
    "- Since our data is at 15-minute intervals, we will resample it to a 1-hour interval by calculating the mean for all values within each hour.\n",
    "- Pandas provides a `resample` method, which will handle this for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "fcb6f9f2-2300-48eb-af29-ea64b781a01a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resample_to_hourly(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Resample 15-minute data to hourly data.\n",
    "    It resamples by calculating mean for each column, this method will not work for \n",
    "    something like precipitaion where we need to do sum instead.\n",
    "    \n",
    "    Args:\n",
    "    df (pd.DataFrame): Input DataFrame with 15-minute data.\n",
    "    value_column (str): Name of the column containing the values to be resampled.\n",
    "    \n",
    "    Returns:\n",
    "    pd.DataFrame: Resampled DataFrame with hourly data.\n",
    "    \"\"\"\n",
    "    \n",
    "    df = df.set_index('DATE')\n",
    "    df = df.sort_index()\n",
    "    \n",
    "    # Resample to hourly frequency, using the mean\n",
    "    resampled = df.resample('h', label='left', closed='left').mean()\n",
    "    \n",
    "    # Reset the index to make the DATE a column again\n",
    "    resampled.reset_index(inplace=True)\n",
    "    resampled.rename(columns={'index': 'DATE'}, inplace=True)\n",
    "\n",
    "    return resampled\n",
    "\n",
    "\n",
    "resampled_df = resample_to_hourly(filled_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "fffab86e-c29c-4221-89ae-848070363bc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 DATE  Unnamed: 0  gauge_height\n",
      "0 2008-01-01 00:00:00         1.5        5.7375\n",
      "1 2008-01-01 01:00:00         5.5        5.6450\n",
      "2 2008-01-01 02:00:00         9.5        5.5425\n",
      "3 2008-01-01 03:00:00        13.5        5.4575\n",
      "4 2008-01-01 04:00:00        17.5        5.3625\n"
     ]
    }
   ],
   "source": [
    "# finally we have the reampled data\n",
    "\n",
    "print(resampled_df.head())\n",
    "\n",
    "# This 'Unnamed: 0' column was originally index column i.e. count for each record. It's values got changed because of pre processing operations. We are going to remove it when saving the final output."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c3b7d96-6356-4229-86f6-d7f8f6b7d886",
   "metadata": {},
   "source": [
    "## Meteorological Data\n",
    "\n",
    "We retrieve the data from this link: <a href='https://www.ncei.noaa.gov/access/search/data-search/local-climatological-data'>https://www.ncei.noaa.gov/access/search/data-search/local-climatological-data</a>.\n",
    "\n",
    "We obtain a CSV file with hourly data, which includes various columns. From these, we will select the following columns:\n",
    "\n",
    "1. DATE\n",
    "2. Wet Bulb Temperature\n",
    "3. Dry Bulb Temperature\n",
    "4. Precipitation\n",
    "5. Relative Humidity\n",
    "6. Wind Speed\n",
    "7. Station Pressure\n",
    "\n",
    "We will apply the same methods as above to this dataset, with small modifications.\n",
    "\n",
    "Let’s start by reading the data into a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f6c0a728-a2dc-4ed5-9c25-d4925400a0a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['STATION', 'DATE', 'REPORT_TYPE', 'SOURCE', 'HourlyAltimeterSetting',\n",
       "       'HourlyDewPointTemperature', 'HourlyDryBulbTemperature',\n",
       "       'HourlyPrecipitation', 'HourlyPresentWeatherType',\n",
       "       'HourlyPressureChange', 'HourlyPressureTendency',\n",
       "       'HourlyRelativeHumidity', 'HourlySeaLevelPressure',\n",
       "       'HourlySkyConditions', 'HourlyStationPressure', 'HourlyVisibility',\n",
       "       'HourlyWetBulbTemperature', 'HourlyWindSpeed'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('Fulton_county_full.csv')\n",
    "\n",
    "# Show all the columns in the csv file\n",
    "data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "619ab906-e2a8-4d39-ba50-00e3802be1d1",
   "metadata": {},
   "source": [
    "We will select a subset of columns as mentioned above.  \n",
    "A dictionary has been created to shorten the column names for convenience."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "eb9ad615-0c9a-4faa-846a-2aa63f258503",
   "metadata": {},
   "outputs": [],
   "source": [
    "name_mapper = {\n",
    "        'DATE': 'DATE',\n",
    "        'HourlyWetBulbTemperature': 'WetBulbTemp',\n",
    "        'HourlyDryBulbTemperature': 'DryBulbTemp',\n",
    "        'HourlyPrecipitation': 'Precip',\n",
    "        'HourlyRelativeHumidity': 'RelHumidity',\n",
    "        'HourlyWindSpeed': 'WindSpeed',\n",
    "        'HourlyStationPressure': 'StationPressure'\n",
    "    }\n",
    "\n",
    "relevant_columns = name_mapper.keys()\n",
    "\n",
    "# Only select the relevant columns and ignore the rest\n",
    "data = data[relevant_columns]\n",
    "\n",
    "# Rename the columns to shorter names for comfort\n",
    "data.rename(columns=name_mapper, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "848d2273-1cd3-4aba-92a3-d69f902820cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DATE</th>\n",
       "      <th>WetBulbTemp</th>\n",
       "      <th>DryBulbTemp</th>\n",
       "      <th>Precip</th>\n",
       "      <th>RelHumidity</th>\n",
       "      <th>WindSpeed</th>\n",
       "      <th>StationPressure</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>22332</th>\n",
       "      <td>2008-01-01T00:53:00</td>\n",
       "      <td>37</td>\n",
       "      <td>38</td>\n",
       "      <td>0.00</td>\n",
       "      <td>89</td>\n",
       "      <td>0.0</td>\n",
       "      <td>29.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22333</th>\n",
       "      <td>2008-01-01T01:53:00</td>\n",
       "      <td>38</td>\n",
       "      <td>39</td>\n",
       "      <td>0.00</td>\n",
       "      <td>89</td>\n",
       "      <td>5.0</td>\n",
       "      <td>29.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22334</th>\n",
       "      <td>2008-01-01T02:53:00</td>\n",
       "      <td>38</td>\n",
       "      <td>40</td>\n",
       "      <td>0.00</td>\n",
       "      <td>86</td>\n",
       "      <td>5.0</td>\n",
       "      <td>29.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22335</th>\n",
       "      <td>2008-01-01T03:53:00</td>\n",
       "      <td>38</td>\n",
       "      <td>40</td>\n",
       "      <td>0.00</td>\n",
       "      <td>86</td>\n",
       "      <td>6.0</td>\n",
       "      <td>29.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22336</th>\n",
       "      <td>2008-01-01T04:53:00</td>\n",
       "      <td>41</td>\n",
       "      <td>45</td>\n",
       "      <td>0.00</td>\n",
       "      <td>68</td>\n",
       "      <td>11.0</td>\n",
       "      <td>29.21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      DATE WetBulbTemp DryBulbTemp Precip RelHumidity  \\\n",
       "22332  2008-01-01T00:53:00          37          38   0.00          89   \n",
       "22333  2008-01-01T01:53:00          38          39   0.00          89   \n",
       "22334  2008-01-01T02:53:00          38          40   0.00          86   \n",
       "22335  2008-01-01T03:53:00          38          40   0.00          86   \n",
       "22336  2008-01-01T04:53:00          41          45   0.00          68   \n",
       "\n",
       "      WindSpeed  StationPressure  \n",
       "22332       0.0            29.19  \n",
       "22333       5.0            29.18  \n",
       "22334       5.0            29.18  \n",
       "22335       6.0            29.19  \n",
       "22336      11.0            29.21  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's look at the dataset\n",
    "data = data[data['DATE'] > '2008-01-01']\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "5ad89312-e75b-4679-9013-a5c457ad4772",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of data that is missing\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DATE                0.000000\n",
       "WetBulbTemp         3.980353\n",
       "DryBulbTemp         3.512513\n",
       "Precip             17.174819\n",
       "RelHumidity         3.711424\n",
       "WindSpeed           3.711955\n",
       "StationPressure     3.558660\n",
       "dtype: float64"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's count the NaN values in the data\n",
    "\n",
    "print(\"Percentage of data that is missing\")\n",
    "data.isna().sum() / len(data)*100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96cd5388-3018-4287-b979-1f2099ed38ee",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "We observe that 17% of the precipitation data is missing (NaN).\n",
    "\n",
    "**Let’s examine this in the dataset.**\n",
    "\n",
    "We find that many values are zero, some are missing, and some are marked as `'T'`.\n",
    "\n",
    "What does `'T'` mean?\n",
    "\n",
    "After some research, we find that in precipitation datasets, `'T'` usually stands for \"Trace,\" indicating a very small amount of precipitation, typically around 0.01 inches or less.\n",
    "\n",
    "Therefore, we will replace `'T'` values with a small value, 0.005."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "1ac92ffa-c51e-49c7-b12b-8aae62a1d3ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Precip'] = data['Precip'].replace('T', 0.005)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29fbcffe-9aab-4788-922e-d57c44d742d2",
   "metadata": {},
   "source": [
    "First we will look at the date gaps like we did above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f4cdb0f0-69ff-4439-96d2-a3f168968444",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert DATE column to datetime object\n",
    "\n",
    "data['DATE'] = pd.to_datetime(data['DATE'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "43702e7b-5a0c-4cf9-ac55-4f44376a372f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing first 20 gaps...\n",
      "\n",
      "Gap found between 2008-01-16 20:22:00 and 2008-01-16 21:53:00: Gap: 0 days 01:31:00\n",
      "Gap found between 2008-01-27 09:50:00 and 2008-01-27 10:53:00: Gap: 0 days 01:03:00\n",
      "Gap found between 2008-03-24 23:59:00 and 2008-03-25 02:53:00: Gap: 0 days 02:54:00\n",
      "Gap found between 2008-07-31 18:53:00 and 2008-07-31 20:53:00: Gap: 0 days 02:00:00\n",
      "Gap found between 2008-08-12 15:52:00 and 2008-08-12 16:53:00: Gap: 0 days 01:01:00\n",
      "Gap found between 2008-11-18 08:52:00 and 2008-11-18 09:56:00: Gap: 0 days 01:04:00\n",
      "Gap found between 2008-11-18 10:52:00 and 2008-11-18 11:53:00: Gap: 0 days 01:01:00\n",
      "Gap found between 2009-07-24 11:53:00 and 2009-07-24 13:53:00: Gap: 0 days 02:00:00\n",
      "Gap found between 2009-08-26 20:53:00 and 2009-08-26 23:59:00: Gap: 0 days 03:06:00\n",
      "Gap found between 2009-09-08 12:51:00 and 2009-09-08 13:53:00: Gap: 0 days 01:02:00\n",
      "Gap found between 2009-11-02 09:53:00 and 2009-11-02 11:53:00: Gap: 0 days 02:00:00\n",
      "Gap found between 2009-11-02 18:53:00 and 2009-11-02 20:53:00: Gap: 0 days 02:00:00\n",
      "Gap found between 2010-03-02 13:51:00 and 2010-03-02 14:53:00: Gap: 0 days 01:02:00\n",
      "Gap found between 2011-07-20 17:53:00 and 2011-07-20 18:54:00: Gap: 0 days 01:01:00\n",
      "Gap found between 2012-06-10 12:48:00 and 2012-06-10 13:53:00: Gap: 0 days 01:05:00\n",
      "Gap found between 2013-06-13 23:59:00 and 2013-06-14 01:53:00: Gap: 0 days 01:54:00\n",
      "Gap found between 2013-07-30 22:53:00 and 2013-07-30 23:59:00: Gap: 0 days 01:06:00\n",
      "Gap found between 2013-07-30 23:59:00 and 2013-07-31 04:53:00: Gap: 0 days 04:54:00\n",
      "Gap found between 2014-02-03 08:50:00 and 2014-02-03 09:53:00: Gap: 0 days 01:03:00\n",
      "Gap found between 2014-08-27 06:53:00 and 2014-08-27 08:53:00: Gap: 0 days 02:00:00\n",
      "\n",
      "Total number of gaps: 39\n",
      "Max gap: 0 days 04:54:00\n",
      "Total gap: 2 days 12:45:00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(Timedelta('0 days 04:54:00'), Timedelta('2 days 12:45:00'))"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find missing dates using the method we wrote above\n",
    "\n",
    "find_missing_dates(data, 'DATE', datetime.timedelta(hours=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "110cc1b6-47b8-401f-a347-e37c6538b12f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non-numeric values in WetBulbTemp:\n",
      "['*']\n",
      "Non-numeric values in DryBulbTemp:\n",
      "['*']\n",
      "Non-numeric values in RelHumidity:\n",
      "['*']\n",
      "Non-numeric values in WindSpeed:\n",
      "['*']\n"
     ]
    }
   ],
   "source": [
    "for col in data.columns:\n",
    "    if col != 'DATE':\n",
    "        # convert non numeric invalid values to NaN\n",
    "        non_numeric_mask = pd.to_numeric(data[col], errors='coerce').isna() & data[col].notna()\n",
    "        non_numeric_values = data.loc[non_numeric_mask, col].unique()\n",
    "        if len(non_numeric_values) > 0:\n",
    "            print(f\"Non-numeric values in {col}:\\n{non_numeric_values}\")\n",
    "        data[col] = pd.to_numeric(data[col], errors='coerce')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6366be69-7c52-4bbd-8c7d-82be39779918",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "We notice there aren’t many gaps in the data, but a few issues need addressing.\n",
    "\n",
    "First, the data is recorded at various minutes within each hour, so the `DATE` column does not align perfectly with hour intervals. As a result, two consecutive records are not always exactly 1 hour apart.\n",
    "\n",
    "We need to write code to correct this.\n",
    "\n",
    "**Defining the Concept:**\n",
    "\n",
    "When we say the precipitation at `2013-06-10 04:00:00` is 0.5 inches, it means the rain gauge height increased by 0.5 inches over the last hour due to rain.\n",
    "\n",
    "So, to adjust our data, we will:\n",
    "1. Loop through each record.\n",
    "2. For a given hour `x`, sum the rainfall that occurred between `x-1` hour and `x` hour.  \n",
    "3. For other columns, calculate the mean of values within that hour.\n",
    "\n",
    "There is an efficient way to accomplish this using Pandas. But before proceeding, let’s ensure all columns are converted to numeric data types."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72dd3d16-e51b-4e54-8a18-10dc1e44354c",
   "metadata": {},
   "source": [
    "And then resample the data to hourly. Note that the following operation ignores the nan values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "9072daae-c67d-4994-a448-28757767c4a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a column with only the hour component\n",
    "data['DATE_hour'] = data['DATE'].dt.ceil('h')  # Rounds up to the nearest hour\n",
    "\n",
    "# Group by the hourly timestamp, summing 'Precip' and averaging other columns\n",
    "hourly_data = data.groupby('DATE_hour').agg({\n",
    "    'Precip': 'sum',\n",
    "    **{col: 'mean' for col in data.columns if col not in ['Precip', 'DATE', 'DATE_hour']}\n",
    "}).reset_index()\n",
    "\n",
    "# Rename DATE_hour back to DATE to match the original structure\n",
    "hourly_data.rename(columns={'DATE_hour': 'DATE'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "25fed8a4-6ea4-4bb0-b09e-2cb3e4c6e123",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DATE</th>\n",
       "      <th>Precip</th>\n",
       "      <th>WetBulbTemp</th>\n",
       "      <th>DryBulbTemp</th>\n",
       "      <th>RelHumidity</th>\n",
       "      <th>WindSpeed</th>\n",
       "      <th>StationPressure</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2008-01-01 01:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>29.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2008-01-01 02:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>29.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2008-01-01 03:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>29.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2008-01-01 04:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>29.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2008-01-01 05:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>29.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143785</th>\n",
       "      <td>2024-05-27 23:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>29.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143786</th>\n",
       "      <td>2024-05-28 00:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>29.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143787</th>\n",
       "      <td>2024-05-28 01:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>29.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143788</th>\n",
       "      <td>2024-05-28 02:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>29.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143789</th>\n",
       "      <td>2024-05-28 03:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>29.07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>143790 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      DATE  Precip  WetBulbTemp  DryBulbTemp  RelHumidity  \\\n",
       "0      2008-01-01 01:00:00     0.0         37.0         38.0         89.0   \n",
       "1      2008-01-01 02:00:00     0.0         38.0         39.0         89.0   \n",
       "2      2008-01-01 03:00:00     0.0         38.0         40.0         86.0   \n",
       "3      2008-01-01 04:00:00     0.0         38.0         40.0         86.0   \n",
       "4      2008-01-01 05:00:00     0.0         41.0         45.0         68.0   \n",
       "...                    ...     ...          ...          ...          ...   \n",
       "143785 2024-05-27 23:00:00     0.0         68.0         73.0         79.0   \n",
       "143786 2024-05-28 00:00:00     0.0         68.0         71.0         87.0   \n",
       "143787 2024-05-28 01:00:00     0.0         67.0         69.0         90.0   \n",
       "143788 2024-05-28 02:00:00     0.0         68.0         69.0         93.0   \n",
       "143789 2024-05-28 03:00:00     0.0         67.0         68.0         93.0   \n",
       "\n",
       "        WindSpeed  StationPressure  \n",
       "0             0.0            29.19  \n",
       "1             5.0            29.18  \n",
       "2             5.0            29.18  \n",
       "3             6.0            29.19  \n",
       "4            11.0            29.21  \n",
       "...           ...              ...  \n",
       "143785        3.0            29.06  \n",
       "143786        0.0            29.07  \n",
       "143787        0.0            29.08  \n",
       "143788        0.0            29.07  \n",
       "143789        0.0            29.07  \n",
       "\n",
       "[143790 rows x 7 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hourly_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f6e3816-6ff6-435d-bf22-0bded6184713",
   "metadata": {},
   "source": [
    "Now, let's fill up the date gaps in the data. We have the method we used previously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "5ed2e7ea-616f-46d2-b996-ab50e2b80aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Let's fill the date gaps\n",
    "\n",
    "hourly_data = fill_missing_dates(hourly_data, freq = '1h' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "4543595b-ef44-418c-839e-20cf07b12000",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DATE               0.000000\n",
       "Precip             0.014602\n",
       "WetBulbTemp        0.734297\n",
       "DryBulbTemp        0.310825\n",
       "RelHumidity        0.438075\n",
       "WindSpeed          0.476320\n",
       "StationPressure    0.318474\n",
       "dtype: float64"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hourly_data.isna().sum() / len(hourly_data) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b71e72a5-ce3c-4742-bf93-3ba7d869a8bb",
   "metadata": {},
   "source": [
    "### Methods to fill the gap in the data\n",
    "We now observe that there are very few gaps, with the percentage being less than 1%.\n",
    "\n",
    "We can use different methods to fill the gap. Examples include \n",
    "\n",
    "- Forward Fill (ffill): This method fills a missing value with the last known non-missing value. This is useful for data where values tend to stay constant between observations.\n",
    "\n",
    "- Backward Fill (bfill): This is the opposite of forward fill. It fills a missing value with the next known non-missing value. This method assumes the value at a missing point is more like what's about to happen than what has already happened.\n",
    "\n",
    "- Mean Fill: This technique calculates the average (mean) of the entire time series and uses that single value to replace all missing data points. It's a very simple approach but can be problematic as it ignores any trends or seasonality and can artificially reduce the variance.\n",
    "\n",
    "- Regression-based Imputation: It treats the variable with missing values as a target and uses other variables (or the time index itself) as predictors in a regression model. The model then predicts what the missing values should be. This can be very effective because it can capture the underlying trends and relationships in the data to make a more intelligent guess.\n",
    "\n",
    "But in our case we will use linear interpolation to fill these gaps, as we did previously for gauge heights, it's similar to mean based method, but we compute mean locally.\n",
    "\n",
    "Since we already implemented this function above, we can simply call it here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "baf38658-401e-4d18-ac93-0361eb7cd9bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "filled_data = fill_missing_values(hourly_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "fd053f7b-5169-471b-9018-c6a3c30ef27d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DATE</th>\n",
       "      <th>Precip</th>\n",
       "      <th>WetBulbTemp</th>\n",
       "      <th>DryBulbTemp</th>\n",
       "      <th>RelHumidity</th>\n",
       "      <th>WindSpeed</th>\n",
       "      <th>StationPressure</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>143811</td>\n",
       "      <td>143811.000000</td>\n",
       "      <td>143811.000000</td>\n",
       "      <td>143811.000000</td>\n",
       "      <td>143811.000000</td>\n",
       "      <td>143811.000000</td>\n",
       "      <td>143811.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2016-03-15 02:00:00</td>\n",
       "      <td>0.013038</td>\n",
       "      <td>56.219143</td>\n",
       "      <td>62.414728</td>\n",
       "      <td>69.734418</td>\n",
       "      <td>4.714649</td>\n",
       "      <td>29.173258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2008-01-01 01:00:00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>28.256667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2012-02-07 01:30:00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>53.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>29.080000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2016-03-15 02:00:00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>59.000000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>73.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>29.170000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2020-04-21 02:30:00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>69.000000</td>\n",
       "      <td>75.000000</td>\n",
       "      <td>88.666667</td>\n",
       "      <td>7.500000</td>\n",
       "      <td>29.270000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2024-05-28 03:00:00</td>\n",
       "      <td>7.200000</td>\n",
       "      <td>81.000000</td>\n",
       "      <td>103.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>29.500000</td>\n",
       "      <td>29.840000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.126359</td>\n",
       "      <td>14.438374</td>\n",
       "      <td>16.251127</td>\n",
       "      <td>20.956541</td>\n",
       "      <td>4.371269</td>\n",
       "      <td>0.154944</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      DATE         Precip    WetBulbTemp    DryBulbTemp  \\\n",
       "count               143811  143811.000000  143811.000000  143811.000000   \n",
       "mean   2016-03-15 02:00:00       0.013038      56.219143      62.414728   \n",
       "min    2008-01-01 01:00:00       0.000000       4.000000       6.000000   \n",
       "25%    2012-02-07 01:30:00       0.000000      45.000000      50.000000   \n",
       "50%    2016-03-15 02:00:00       0.000000      59.000000      64.000000   \n",
       "75%    2020-04-21 02:30:00       0.000000      69.000000      75.000000   \n",
       "max    2024-05-28 03:00:00       7.200000      81.000000     103.000000   \n",
       "std                    NaN       0.126359      14.438374      16.251127   \n",
       "\n",
       "         RelHumidity      WindSpeed  StationPressure  \n",
       "count  143811.000000  143811.000000    143811.000000  \n",
       "mean       69.734418       4.714649        29.173258  \n",
       "min        10.000000       0.000000        28.256667  \n",
       "25%        53.000000       0.000000        29.080000  \n",
       "50%        73.000000       5.000000        29.170000  \n",
       "75%        88.666667       7.500000        29.270000  \n",
       "max       100.000000      29.500000        29.840000  \n",
       "std        20.956541       4.371269         0.154944  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filled_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "0de9e993-83c6-4d48-a873-552123a1f923",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DATE               0\n",
       "Precip             0\n",
       "WetBulbTemp        0\n",
       "DryBulbTemp        0\n",
       "RelHumidity        0\n",
       "WindSpeed          0\n",
       "StationPressure    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for NaN values\n",
    "filled_data.isna().sum() # Meterological data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "90c64ec3-17f0-4350-b7b9-ae5eb88a3987",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DATE            0\n",
       "Unnamed: 0      0\n",
       "gauge_height    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resampled_df.isna().sum() # Gauge height data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c632f4c-0f6c-474a-91dd-965b44d0e0a4",
   "metadata": {},
   "source": [
    "***In the next step, we will combine the dataframes and save them in a single file for future use.***\n",
    "\n",
    "Below is the method to combine the dataframes. It uses the `DATE` column as the common column to merge them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "b1d319cd-6c14-4809-bfdf-b25ee45f2746",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_dataframes(df1, df2, common_col = 'DATE'):\n",
    "\n",
    "    # set the common column 'DATE' as index\n",
    "    df1.set_index(common_col, inplace=True)\n",
    "    df2.set_index(common_col, inplace=True)\n",
    "\n",
    "    # min_date is the maximum start date from both dataframes\n",
    "    min_date = max(df1.index.min(), df2.index.min())\n",
    "\n",
    "    # max_date is the minimum end date from both dataframes\n",
    "    max_date = min(df1.index.max(), df2.index.max())\n",
    "\n",
    "    # combine the dataframes\n",
    "    df = pd.concat([df1, df2], axis = 1)\n",
    "    \n",
    "    df = df[min_date:max_date]\n",
    "    df.reset_index(inplace=True)\n",
    "    df.rename(columns={'index': 'DATE'}, inplace=True)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "49ce72e2-1113-48ae-84fc-cdcd0f7909e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df = combine_dataframes(filled_data, resampled_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "d47d6057-f000-4d27-9ffa-d85cbe1c57b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DATE</th>\n",
       "      <th>Precip</th>\n",
       "      <th>WetBulbTemp</th>\n",
       "      <th>DryBulbTemp</th>\n",
       "      <th>RelHumidity</th>\n",
       "      <th>WindSpeed</th>\n",
       "      <th>StationPressure</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>gauge_height</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2008-01-01 01:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>29.19</td>\n",
       "      <td>5.5</td>\n",
       "      <td>5.6450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2008-01-01 02:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>29.18</td>\n",
       "      <td>9.5</td>\n",
       "      <td>5.5425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2008-01-01 03:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>29.18</td>\n",
       "      <td>13.5</td>\n",
       "      <td>5.4575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2008-01-01 04:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>29.19</td>\n",
       "      <td>17.5</td>\n",
       "      <td>5.3625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2008-01-01 05:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>29.21</td>\n",
       "      <td>21.5</td>\n",
       "      <td>5.2175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143806</th>\n",
       "      <td>2024-05-27 23:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>29.06</td>\n",
       "      <td>571057.5</td>\n",
       "      <td>7.2175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143807</th>\n",
       "      <td>2024-05-28 00:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>29.07</td>\n",
       "      <td>571061.5</td>\n",
       "      <td>7.0725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143808</th>\n",
       "      <td>2024-05-28 01:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>29.08</td>\n",
       "      <td>571065.5</td>\n",
       "      <td>6.9625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143809</th>\n",
       "      <td>2024-05-28 02:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>29.07</td>\n",
       "      <td>571069.5</td>\n",
       "      <td>6.8675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143810</th>\n",
       "      <td>2024-05-28 03:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>29.07</td>\n",
       "      <td>571073.5</td>\n",
       "      <td>6.7950</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>143811 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      DATE  Precip  WetBulbTemp  DryBulbTemp  RelHumidity  \\\n",
       "0      2008-01-01 01:00:00     0.0         37.0         38.0         89.0   \n",
       "1      2008-01-01 02:00:00     0.0         38.0         39.0         89.0   \n",
       "2      2008-01-01 03:00:00     0.0         38.0         40.0         86.0   \n",
       "3      2008-01-01 04:00:00     0.0         38.0         40.0         86.0   \n",
       "4      2008-01-01 05:00:00     0.0         41.0         45.0         68.0   \n",
       "...                    ...     ...          ...          ...          ...   \n",
       "143806 2024-05-27 23:00:00     0.0         68.0         73.0         79.0   \n",
       "143807 2024-05-28 00:00:00     0.0         68.0         71.0         87.0   \n",
       "143808 2024-05-28 01:00:00     0.0         67.0         69.0         90.0   \n",
       "143809 2024-05-28 02:00:00     0.0         68.0         69.0         93.0   \n",
       "143810 2024-05-28 03:00:00     0.0         67.0         68.0         93.0   \n",
       "\n",
       "        WindSpeed  StationPressure  Unnamed: 0  gauge_height  \n",
       "0             0.0            29.19         5.5        5.6450  \n",
       "1             5.0            29.18         9.5        5.5425  \n",
       "2             5.0            29.18        13.5        5.4575  \n",
       "3             6.0            29.19        17.5        5.3625  \n",
       "4            11.0            29.21        21.5        5.2175  \n",
       "...           ...              ...         ...           ...  \n",
       "143806        3.0            29.06    571057.5        7.2175  \n",
       "143807        0.0            29.07    571061.5        7.0725  \n",
       "143808        0.0            29.08    571065.5        6.9625  \n",
       "143809        0.0            29.07    571069.5        6.8675  \n",
       "143810        0.0            29.07    571073.5        6.7950  \n",
       "\n",
       "[143811 rows x 9 columns]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "19f58566-ef5a-4454-9f5b-cb58947174c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's get rid of the Unnamed column\n",
    "\n",
    "combined_df.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "\n",
    "# set 'DATE' column as index\n",
    "\n",
    "combined_df.set_index('DATE', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "fe79272b-7c1d-4c17-b8ee-f2353e916a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save it in a dataframe to be used later\n",
    "\n",
    "combined_df.to_csv('final_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "64150d3a-1ea6-4ff0-8996-8e4789ac8661",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Precip</th>\n",
       "      <th>WetBulbTemp</th>\n",
       "      <th>DryBulbTemp</th>\n",
       "      <th>RelHumidity</th>\n",
       "      <th>WindSpeed</th>\n",
       "      <th>StationPressure</th>\n",
       "      <th>gauge_height</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DATE</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2008-01-01 01:00:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>29.19</td>\n",
       "      <td>5.6450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008-01-01 02:00:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>29.18</td>\n",
       "      <td>5.5425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008-01-01 03:00:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>29.18</td>\n",
       "      <td>5.4575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008-01-01 04:00:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>29.19</td>\n",
       "      <td>5.3625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008-01-01 05:00:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>29.21</td>\n",
       "      <td>5.2175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-05-27 23:00:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>29.06</td>\n",
       "      <td>7.2175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-05-28 00:00:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>29.07</td>\n",
       "      <td>7.0725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-05-28 01:00:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>29.08</td>\n",
       "      <td>6.9625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-05-28 02:00:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>29.07</td>\n",
       "      <td>6.8675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-05-28 03:00:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>29.07</td>\n",
       "      <td>6.7950</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>143811 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Precip  WetBulbTemp  DryBulbTemp  RelHumidity  WindSpeed  \\\n",
       "DATE                                                                            \n",
       "2008-01-01 01:00:00     0.0         37.0         38.0         89.0        0.0   \n",
       "2008-01-01 02:00:00     0.0         38.0         39.0         89.0        5.0   \n",
       "2008-01-01 03:00:00     0.0         38.0         40.0         86.0        5.0   \n",
       "2008-01-01 04:00:00     0.0         38.0         40.0         86.0        6.0   \n",
       "2008-01-01 05:00:00     0.0         41.0         45.0         68.0       11.0   \n",
       "...                     ...          ...          ...          ...        ...   \n",
       "2024-05-27 23:00:00     0.0         68.0         73.0         79.0        3.0   \n",
       "2024-05-28 00:00:00     0.0         68.0         71.0         87.0        0.0   \n",
       "2024-05-28 01:00:00     0.0         67.0         69.0         90.0        0.0   \n",
       "2024-05-28 02:00:00     0.0         68.0         69.0         93.0        0.0   \n",
       "2024-05-28 03:00:00     0.0         67.0         68.0         93.0        0.0   \n",
       "\n",
       "                     StationPressure  gauge_height  \n",
       "DATE                                                \n",
       "2008-01-01 01:00:00            29.19        5.6450  \n",
       "2008-01-01 02:00:00            29.18        5.5425  \n",
       "2008-01-01 03:00:00            29.18        5.4575  \n",
       "2008-01-01 04:00:00            29.19        5.3625  \n",
       "2008-01-01 05:00:00            29.21        5.2175  \n",
       "...                              ...           ...  \n",
       "2024-05-27 23:00:00            29.06        7.2175  \n",
       "2024-05-28 00:00:00            29.07        7.0725  \n",
       "2024-05-28 01:00:00            29.08        6.9625  \n",
       "2024-05-28 02:00:00            29.07        6.8675  \n",
       "2024-05-28 03:00:00            29.07        6.7950  \n",
       "\n",
       "[143811 rows x 7 columns]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b49495a4-0edb-491e-9149-d42500bba58f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
