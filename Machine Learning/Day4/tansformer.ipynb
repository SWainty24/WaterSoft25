{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9ccae883-1904-48a6-81b3-d0228caeab1f",
   "metadata": {},
   "source": [
    "\n",
    "## Multivariate time series prediction using Transformer\n",
    "\n",
    "\n",
    "### In this document we explain how a Transformer encoder network is supposed to process information. \n",
    "<i> Note: We use PatchTST which is a popular time series forecasting model that uses a Transformer Encoder to make predictions</i>\n",
    "\n",
    "The multi-head attention functionality.\n",
    "\n",
    "Let's suppose the input to the model is a sequence given by\n",
    "$$[x_1, x_2, x_3, ..., x_{12}]$$ (these are tokens input to the model)\n",
    "\n",
    "We first reshape it into a following matrix (called embeddings) of some patch size let's say 4.\n",
    "$$ Input (I) = \\begin{bmatrix}\n",
    "x_1 & x_2 & x_3 & x_4 \\\\\n",
    "x_5 & x_6 & x_7 & x_8 \\\\\n",
    "x_9 & x_{10} & x_{11} & x_{12} \\\\  \n",
    "\\end{bmatrix}^T = \n",
    "\\begin{bmatrix}\n",
    "x_1 & x_5 & x_9  \\\\\n",
    "x_2 & x_6 & x_{10} \\\\\n",
    "x_3 & x_7 & x_{11} \\\\\n",
    "x_4 & x_8 & x_{12}\n",
    "\\end{bmatrix}  (4 \\times 3)\n",
    "$$\n",
    "\n",
    "We use a fc layer of shape let's name it $( 3 \\times 10)$, (this is called enriching embeddings with the positional encodings to retain the sequence order information), the output of this process is a $(4 \\times 10)$ matrix. Let's denote the output matrix by say $x_d$\n",
    "\n",
    "Now the output of the FC layer is passed through the multi-head attention block.\n",
    "The number of heads can be any number you can define. I will explain what happens in one of those heads. \n",
    "\n",
    "Each head has three matrices, let's name them $W_Q, W_K, W_V.$\n",
    "We compute the following.\n",
    "$$ Q_h = x_d \\times W_Q $$\n",
    "$$ K_h = x_d \\times W_K $$\n",
    "$$ V_h = x_d \\times W_V $$\n",
    "\n",
    "Note that the no. of columns of Q, K, V is equal to some value let's say $d_k$ (user-defined)\n",
    "\n",
    "The attention value for a head is calculated as \n",
    "$$\n",
    "O_h = softmax\\left( \\frac{Q_h K_h^T}{\\sqrt{d_k}} \\right) V_h\n",
    "$$\n",
    "\n",
    "Let's suppose the output $O_h$ has dimensions $(4 \\times 10)$\n",
    "\n",
    "In general there are multiple heads, so we have output of attention heads as $O_1, O_2, ..., O_h$. \\\n",
    "The attention heads are concatenated to get multi head attention\n",
    "$$O_{multi-head} = Concat(O_1, O_2, O_3, ... , O_h)$$\n",
    "\n",
    "A weight matrix $W^o$ (Output Projection Matrix) is used to bring back the $O_{multi-head}$ to the shape of $x_d$.\n",
    "And we compute\n",
    "\n",
    "$O' = O_{multi-head} \\times W^o$ \\\n",
    "and we calculate residuals as \\\n",
    "$O_{residual} = O' + x_d$\n",
    "\n",
    "This $O_{residual}$ is the input to the feedforward network to get the required output.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c3f8bb5-7463-4aaf-ba28-9a466bad685a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4117e9d0-7925-4788-bbe1-28c60c80bb56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8af4f85b-3822-4288-9566-0f0ac0cfa053",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../dataset/chattahoochee_3hr_02336490.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fc9eb646-4308-449c-84c0-00cd1de182c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0600e784-ec1c-4ab8-ab6b-9b765b4dee83",
   "metadata": {},
   "source": [
    "Here we define **RiverData** a custom Dataset class to load the dataset we have. It extends the Pytorch Dataset class.  \n",
    "- We need to define \\_\\_init__() function which can be used for loading data from the file and optionally for data preprocessing.\n",
    "- Thereafter we define \\_\\_len__() function which gives the length of dataset.\n",
    "- Then we define \\_\\_getitem__() function which returns an instance of (feature, label) tuple which can be used for model training.\n",
    "  For our time series data, feature means the past values to be used for training and label means the future values to be predicted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "742b694d-9966-4fd3-bca7-51f398a8775f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RiverData(torch.utils.data.Dataset):\n",
    "    \n",
    "    def __init__(self, df, target, datecol, seq_len, pred_len):\n",
    "        self.df = df\n",
    "        self.datecol = datecol\n",
    "        self.target = target\n",
    "        self.seq_len = seq_len\n",
    "        self.pred_len = pred_len\n",
    "        self.setIndex()\n",
    "        \n",
    "\n",
    "    def setIndex(self):\n",
    "        self.df.set_index(self.datecol, inplace=True)\n",
    "    \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df) - self.seq_len - self.pred_len\n",
    "\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if len(self.df) <= (idx + self.seq_len+self.pred_len):\n",
    "            raise IndexError(f\"Index {idx} is out of bounds for dataset of size {len(self.df)}\")\n",
    "        df_piece = self.df[idx:idx+self.seq_len].values\n",
    "        feature = torch.tensor(df_piece, dtype=torch.float32)\n",
    "        label_piece = self.df[self.target][idx + self.seq_len:  idx+self.seq_len+self.pred_len].values\n",
    "        label = torch.tensor(label_piece, dtype=torch.float32)\n",
    "        return (feature, label) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60c24959-e72f-435d-8a14-69a648fa5ab1",
   "metadata": {},
   "source": [
    "### Normalize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "46d897d9-946e-4bbe-90a6-cc8d8a223c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(path)\n",
    "raw_df = df.drop('DATE', axis=1, inplace=False)\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Apply the transformations\n",
    "df_scaled = scaler.fit_transform(raw_df)\n",
    "\n",
    "df_scaled = pd.DataFrame(df_scaled, columns=raw_df.columns)\n",
    "df_scaled['DATE'] = df['DATE']\n",
    "df = df_scaled"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a4781c6-88ed-4b28-aa0e-f669bf7c75f5",
   "metadata": {},
   "source": [
    "Some advanced Python syntax has been used here. \\\n",
    "*common_args : it's used to pass arguments to a function, where common_args represents a python list \\\n",
    "**common_args: it's used to pass arguments to a function, where common_args represents a python dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9e63a535-a817-4429-be17-f3e3a02e4f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_size = int(0.7 * len(df))\n",
    "test_size = int(0.2 * len(df))\n",
    "val_size = len(df) - train_size - test_size\n",
    "\n",
    "seq_len = 8\n",
    "pred_len = 1\n",
    "num_features = 7\n",
    "num_layers = 1\n",
    "\n",
    "\n",
    "common_args = ['gaze_height', 'DATE', seq_len, pred_len]\n",
    "train_dataset = RiverData(df[:train_size], *common_args)\n",
    "val_dataset = RiverData(df[train_size: train_size+val_size], *common_args)\n",
    "test_dataset = RiverData(df[train_size+val_size : len(df)], *common_args)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "501879b1-dd1c-4ff0-afb3-ff25a345df05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Important parameters\n",
    "\n",
    "BATCH_SIZE = 512 # keep as big as can be handled by GPU and memory\n",
    "SHUFFLE = False # we don't shuffle the time series data\n",
    "DATA_LOAD_WORKERS = 1 # it depends on amount of data you need to load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ae359aec-9435-4229-8587-5f120b0370b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "common_args = {'batch_size': BATCH_SIZE, 'shuffle': SHUFFLE}\n",
    "train_loader = DataLoader(train_dataset, **common_args)\n",
    "val_loader = DataLoader(val_dataset, **common_args)\n",
    "test_loader = DataLoader(test_dataset, **common_args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc7ac35c-8ecc-4ab7-a97c-0cb4d59bc624",
   "metadata": {},
   "source": [
    "### Here we define our PyTorch model.\n",
    "\n",
    "BasicTransformerNetwork is the model class, it extends the Module class provided by Pytorch. \\\n",
    "- We define \\_\\_init__() function. It sets up layers and defines the model parameters.\n",
    "- Also, we define forward() function which defines how the forwared pass computation occurs\n",
    "- We also implement PositionalEncoding class which is an important part of transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "01cd8d0d-2058-4dfe-9046-78cde5fd2f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The transformer implementation in Pytorch doesn't implement the \n",
    "# positional encoding which is an essential part of the Transformer model\n",
    "# Positional Encoding explanation at depth: https://www.youtube.com/watch?v=dichIcUZfOw\n",
    "class PositionalEncoding(torch.nn.Module):\n",
    "    def __init__(self, d_model, dropout=0.1, max_len=5000):\n",
    "        super().__init__();\n",
    "        self.dropout = torch.nn.Dropout(p=dropout)\n",
    "\n",
    "        Xp = torch.zeros(max_len, d_model) # max_len x d_model\n",
    "        position = torch.arange(0, max_len).unsqueeze(1) # max_len x 1\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2) * (-math.log(100000.0) / d_model)) #length: d_model/2\n",
    "\n",
    "        #Applying sine to even indices in the array; 2i\n",
    "        Xp[:, 0::2] = torch.sin(position.float() * div_term)\n",
    "\n",
    "        #Applying cosine to odd indices in the array; 2i + 1\n",
    "        Xp[:, 1::2] = torch.cos(position.float() * div_term)\n",
    "\n",
    "        Xp = Xp.unsqueeze(1)\n",
    "        self.register_buffer('Xp', Xp)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x  = x + self.Xp[:x.size(0)]\n",
    "        return self.dropout(x)\n",
    "\n",
    "\n",
    "class BasicTransformerNetwork(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self, seq_len, pred_len):\n",
    "        # call the constructor of the base class\n",
    "        super().__init__()\n",
    "        self.model_type = 'Transformer'\n",
    "        self.seq_len = seq_len\n",
    "        self.pred_len = pred_len\n",
    "        self.num_features = num_features\n",
    "\n",
    "        # I don't think the embedding size should be this big. We will see.\n",
    "        self.embedding_size = 128 #The features are converted to 512 embeddings\n",
    "        self.num_layers = num_layers\n",
    "        self.pos_encoder = PositionalEncoding(self.embedding_size, 0.1, 10000)\n",
    "        \n",
    "        \n",
    "        self.encLayer = torch.nn.TransformerEncoderLayer(d_model=self.embedding_size, nhead=8, \n",
    "                                                 dim_feedforward=256, dropout=0.1, activation=\"relu\", \n",
    "                                                 layer_norm_eps=1e-05, batch_first=True, norm_first=False, bias=True, \n",
    "                                                 device=None, dtype=None)\n",
    "        \n",
    "        self.transformerEnc = torch.nn.TransformerEncoder(self.encLayer, num_layers=self.num_layers)\n",
    "\n",
    "        self.input_fc = torch.nn.Linear(self.num_features, self.embedding_size)\n",
    "        self.relu = torch.nn.ReLU()\n",
    "        \n",
    "        self.output_fc1 = torch.nn.Linear(self.embedding_size, self.pred_len)\n",
    "        self.output_fc2 = torch.nn.Linear(self.seq_len, 1)\n",
    "\n",
    "        \n",
    "\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.input_fc(x) * np.sqrt(self.embedding_size)\n",
    "        x = self.pos_encoder(x)\n",
    "        out = self.transformerEnc(x)\n",
    "        out = self.output_fc1(out) # dimension 512 x seq_len x pred_len\n",
    "        out = out.transpose(1,2) # dimension 512 x pred_len x seq_len\n",
    "        out = self.output_fc2(out) # dimension 512 x pred_len x 1\n",
    "        out = out.squeeze(-1) # dimension 512 x pred_len\n",
    "        return out\n",
    "# Note that the gradients are stored inside the FC layer objects\n",
    "# For each training example we need to get rid of these gradients"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f579dc18-584e-414b-ae8e-37f62e4b42f3",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b600c877-3409-48f9-80e5-3fdde7731817",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4.1+cu121\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5277794b-fe37-4595-8554-d26db5710e44",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BasicTransformerNetwork(seq_len, pred_len)\n",
    "loss = torch.nn.MSELoss()\n",
    "learning_rate = 2e-2\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr = learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1afde643-9953-4129-8415-7b4836c31300",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([384, 128])\n",
      "torch.Size([384])\n",
      "torch.Size([128, 128])\n",
      "torch.Size([128])\n",
      "torch.Size([256, 128])\n",
      "torch.Size([256])\n",
      "torch.Size([128, 256])\n",
      "torch.Size([128])\n",
      "torch.Size([128])\n",
      "torch.Size([128])\n",
      "torch.Size([128])\n",
      "torch.Size([128])\n",
      "torch.Size([384, 128])\n",
      "torch.Size([384])\n",
      "torch.Size([128, 128])\n",
      "torch.Size([128])\n",
      "torch.Size([256, 128])\n",
      "torch.Size([256])\n",
      "torch.Size([128, 256])\n",
      "torch.Size([128])\n",
      "torch.Size([128])\n",
      "torch.Size([128])\n",
      "torch.Size([128])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 7])\n",
      "torch.Size([128])\n",
      "torch.Size([1, 128])\n",
      "torch.Size([1])\n",
      "torch.Size([1, 8])\n",
      "torch.Size([1])\n"
     ]
    }
   ],
   "source": [
    "for gen in model.parameters():\n",
    "    print(gen.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4b3cc7a8-9844-4eae-a601-4787513eb1cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features shape:  torch.Size([512, 8, 7])\n",
      "labels shape:  torch.Size([512, 1])\n"
     ]
    }
   ],
   "source": [
    "for i, (f,l) in enumerate(train_loader):\n",
    "    print('features shape: ', f.shape)\n",
    "    print('labels shape: ', l.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "22683e91-642a-494b-abc5-069dc6fa9eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define metrics\n",
    "import numpy as np\n",
    "epsilon = np.finfo(float).eps\n",
    "\n",
    "def Wape(y, y_pred):\n",
    "    \"\"\"Weighted Average Percentage Error metric in the interval [0; 100]\"\"\"\n",
    "    y = np.array(y)\n",
    "    y_pred = np.array(y_pred)\n",
    "    nominator = np.sum(np.abs(np.subtract(y, y_pred)))\n",
    "    denominator = np.add(np.sum(np.abs(y)), epsilon)\n",
    "    wape = np.divide(nominator, denominator) * 100.0\n",
    "    return wape\n",
    "\n",
    "def nse(y, y_pred):\n",
    "    y = np.array(y)\n",
    "    y_pred = np.array(y_pred)\n",
    "    return (1-(np.sum((y_pred-y)**2)/np.sum((y-np.mean(y))**2)))\n",
    "\n",
    "\n",
    "def evaluate_model(model, data_loader):\n",
    "    # following line prepares the model for evaluation mode. It disables dropout and batch normalization if they have \n",
    "    # are part of the model. For our simple model, it's not necessary. Still, we're going to use it.\n",
    "\n",
    "    model.eval()\n",
    "    all_inputs = torch.empty((0, seq_len, num_features))\n",
    "    all_labels = torch.empty(0, pred_len)\n",
    "    for inputs, labels in data_loader:\n",
    "        all_inputs = torch.vstack((all_inputs, inputs))\n",
    "        all_labels = torch.vstack((all_labels, labels))\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(all_inputs)\n",
    "        nsee = nse(all_labels.numpy(), outputs.numpy())\n",
    "        wapee = Wape(all_labels.numpy(), outputs.numpy())\n",
    "        \n",
    "    print(f'NSE : {nsee}', end=' ')\n",
    "    print(f'WAPE : {wapee}')\n",
    "    \n",
    "    model.train()\n",
    "    return nsee, wapee\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9beaf3a1-2c40-4fc6-b0f7-c352b5763231",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: 0.714999140465054 NSE : 0.7348496317863464 WAPE : 45.39845270828188\n",
      "Epoch 2: 0.1955247903563853 NSE : 0.7820141315460205 WAPE : 40.96390630223869\n",
      "Epoch 3: 0.17008889106840924 NSE : 0.8025670051574707 WAPE : 38.81286320656038\n",
      "Epoch 4: 0.151541979533845 NSE : 0.8267194628715515 WAPE : 35.45371778186328\n",
      "Epoch 5: 0.13934566896280337 NSE : 0.837936282157898 WAPE : 34.616803840922614\n",
      "Epoch 6: 0.13237792767327408 NSE : 0.8477243781089783 WAPE : 33.55349209442247\n",
      "Epoch 7: 0.122721536727301 NSE : 0.8571048378944397 WAPE : 31.98352735849241\n",
      "Epoch 8: 0.11997186193435357 NSE : 0.8642688989639282 WAPE : 31.370909455867125\n",
      "Epoch 9: 0.11297177606872444 NSE : 0.8692455887794495 WAPE : 30.887718054278384\n",
      "Epoch 10: 0.10870296206196835 NSE : 0.8722795248031616 WAPE : 30.456497328311684\n",
      "Epoch 11: 0.10756489261984825 NSE : 0.874014675617218 WAPE : 29.87379946729161\n",
      "Epoch 12: 0.10391822906917539 NSE : 0.8785779476165771 WAPE : 28.88838345097799\n",
      "Epoch 13: 0.10364194843789627 NSE : 0.880643367767334 WAPE : 28.622485455444814\n",
      "Epoch 14: 0.10054133048859136 NSE : 0.8833005428314209 WAPE : 28.93690657660893\n",
      "Epoch 15: 0.09758307139292874 NSE : 0.8878641128540039 WAPE : 28.073930721841368\n",
      "Epoch 16: 0.09526181221008301 NSE : 0.892677903175354 WAPE : 27.14592390755352\n",
      "Epoch 17: 0.09529761860853639 NSE : 0.8903936743736267 WAPE : 28.16698198606251\n",
      "Epoch 18: 0.09382040888584893 NSE : 0.8954411745071411 WAPE : 27.11891049599752\n",
      "Epoch 19: 0.09217140162042503 NSE : 0.8975270986557007 WAPE : 27.105859987760873\n",
      "Epoch 20: 0.09287122123200318 NSE : 0.8989385962486267 WAPE : 27.00874856542166\n",
      "Epoch 21: 0.09115367305689845 NSE : 0.90119868516922 WAPE : 26.471575960475047\n",
      "Epoch 22: 0.08843597782583072 NSE : 0.9022020697593689 WAPE : 26.466683241844002\n",
      "Epoch 23: 0.08614943337080808 NSE : 0.9030827879905701 WAPE : 26.2573455950543\n",
      "Epoch 24: 0.08863195873283107 NSE : 0.902755618095398 WAPE : 26.910824133892675\n",
      "Epoch 25: 0.08697176782478547 NSE : 0.9045447707176208 WAPE : 26.545157365341893\n",
      "Epoch 26: 0.08202509983474839 NSE : 0.9098117351531982 WAPE : 25.15744028862967\n",
      "Epoch 27: 0.0853995983328285 NSE : 0.9089667797088623 WAPE : 25.230862024357037\n",
      "Epoch 28: 0.0894745859349596 NSE : 0.9088264107704163 WAPE : 25.33929366282961\n",
      "Epoch 29: 0.08232630439231108 NSE : 0.9111422300338745 WAPE : 24.876209167876134\n",
      "Epoch 30: 0.08892623698017721 NSE : 0.9095177054405212 WAPE : 25.78771303610543\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 30\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    epoch_loss = []\n",
    "    for batch_idx, (inputs, labels) in enumerate(train_loader):\n",
    "        outputs = model(inputs)\n",
    "        loss_val = loss(outputs, labels)\n",
    "\n",
    "        # calculate gradients for back propagation\n",
    "        loss_val.backward()\n",
    "\n",
    "        # update the weights based on the gradients\n",
    "        optimizer.step()\n",
    "\n",
    "        # reset the gradients, avoid gradient accumulation\n",
    "        optimizer.zero_grad()\n",
    "        epoch_loss.append(loss_val.item())\n",
    "    \n",
    "    print(f'Epoch {epoch+1}: {sum(epoch_loss)/len(epoch_loss)}', end=' ')\n",
    "    nsee, wapee = evaluate_model(model, val_loader)\n",
    "    \n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f7216e93-a35d-4aa5-83db-2e43ea380f6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NSE : 0.8960729837417603 WAPE : 29.622249249767947\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(np.float32(0.896073), np.float64(29.622249249767947))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_model(model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "722fee71-de14-463f-abf6-e35f9f002ae1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a2f592f-d2be-4ea2-9e9e-d034d45f551d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c474aced-89cf-41c7-ae2c-b98c4b87b1b9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
