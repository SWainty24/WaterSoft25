{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9ccae883-1904-48a6-81b3-d0228caeab1f",
   "metadata": {},
   "source": [
    "\n",
    "## Multivariate time series prediction using Transformer\n",
    "\n",
    "\n",
    "### In this document I will explain how a transformer encoder network is supposed to process information based on my knowledge. \n",
    "<i> Note: PatchTST is a popular timeseries forecasting model which uses Transformer Encoder to make predictions</i>\n",
    "\n",
    "I will explain the way the multi head attention works here.\n",
    "\n",
    "Let's suppose the input to the model is a sequence given by\n",
    "$$[x_1, x_2, x_3, ..., x_{12}]$$ (these are tokens input to the model)\n",
    "\n",
    "We first reshape it into a following matrix (called embeddings) of some patch size say 4.\n",
    "$$ Input (I) = \\begin{bmatrix}\n",
    "x_1 & x_2 & x_3 & x_4 \\\\\n",
    "x_5 & x_6 & x_7 & x_8 \\\\\n",
    "x_9 & x_{10} & x_{11} & x_{12} \\\\  \n",
    "\\end{bmatrix}^T = \n",
    "\\begin{bmatrix}\n",
    "x_1 & x_5 & x_9  \\\\\n",
    "x_2 & x_6 & x_{10} \\\\\n",
    "x_3 & x_7 & x_{11} \\\\\n",
    "x_4 & x_8 & x_{12}\n",
    "\\end{bmatrix}  (4 \\times 3)\n",
    "$$\n",
    "\n",
    "We use a fc layer of shape say $( 3 \\times 10)$, (this is called enriching embeddings with the positional encodings to retain the sequence order information), the output of this process is a $(4 \\times 10)$ matrix. Let's denote the output matrix by say $x_d$\n",
    "\n",
    "Now the output of FC layer is passed through the multi-head attention block.\n",
    "The number of heads can be any number you can define. I will explain what happens in one of those head. \n",
    "\n",
    "Each head has three matrices, let's say them $W_Q, W_K, W_V.$\n",
    "We compute the following.\n",
    "$$ Q_h = x_d \\times W_Q $$\n",
    "$$ K_h = x_d \\times W_K $$\n",
    "$$ V_h = x_d \\times W_V $$\n",
    "\n",
    "Note that the no. of columns of Q, K, V is equal to some value say $d_k$ (user defined)\n",
    "\n",
    "The attention value for a head is calculated as \n",
    "$$\n",
    "O_h = softmax\\left( \\frac{Q_h K_h^T}{\\sqrt{d_k}} \\right) V_h\n",
    "$$\n",
    "\n",
    "Let's suppose the output $O_h$ has dimensions $(4 \\times 10)$\n",
    "\n",
    "In general there are multiple heads, so we have output of attention heads as $O_1, O_2, ..., O_h$. \\\n",
    "The attention heads are concatenated to get multi head attention\n",
    "$$O_{multi-head} = Concat(O_1, O_2, O_3, ... , O_h)$$\n",
    "\n",
    "A weight matrix $W^o$ (Output Projection Matrix) is used to bring back the $O_{multi-head}$ to the shape of $x_d$.\n",
    "And we compute\n",
    "\n",
    "$O' = O_{multi-head} \\times W^o$ \\\n",
    "and we calculate residuals as \\\n",
    "$O_{residual} = O' + x_d$\n",
    "\n",
    "This $O_{residual}$ is the input to the feedforward network to get the required output.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c3f8bb5-7463-4aaf-ba28-9a466bad685a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4117e9d0-7925-4788-bbe1-28c60c80bb56",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.1.0 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"/Users/cuser/Documents/cybertraining/venv/lib/python3.12/site-packages/ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/Users/cuser/Documents/cybertraining/venv/lib/python3.12/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"/Users/cuser/Documents/cybertraining/venv/lib/python3.12/site-packages/ipykernel/kernelapp.py\", line 739, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/Users/cuser/Documents/cybertraining/venv/lib/python3.12/site-packages/tornado/platform/asyncio.py\", line 205, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/usr/local/Cellar/python@3.12/3.12.6/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/base_events.py\", line 641, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/usr/local/Cellar/python@3.12/3.12.6/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/base_events.py\", line 1986, in _run_once\n",
      "    handle._run()\n",
      "  File \"/usr/local/Cellar/python@3.12/3.12.6/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/events.py\", line 88, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"/Users/cuser/Documents/cybertraining/venv/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 545, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"/Users/cuser/Documents/cybertraining/venv/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 534, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"/Users/cuser/Documents/cybertraining/venv/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 437, in dispatch_shell\n",
      "    await result\n",
      "  File \"/Users/cuser/Documents/cybertraining/venv/lib/python3.12/site-packages/ipykernel/ipkernel.py\", line 362, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"/Users/cuser/Documents/cybertraining/venv/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 778, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"/Users/cuser/Documents/cybertraining/venv/lib/python3.12/site-packages/ipykernel/ipkernel.py\", line 449, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"/Users/cuser/Documents/cybertraining/venv/lib/python3.12/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"/Users/cuser/Documents/cybertraining/venv/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3075, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"/Users/cuser/Documents/cybertraining/venv/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3130, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"/Users/cuser/Documents/cybertraining/venv/lib/python3.12/site-packages/IPython/core/async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/Users/cuser/Documents/cybertraining/venv/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3334, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"/Users/cuser/Documents/cybertraining/venv/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3517, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"/Users/cuser/Documents/cybertraining/venv/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3577, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/var/folders/j3/9_pszf256zvgnry9z0x72k_h0000gn/T/ipykernel_85947/2055104542.py\", line 1, in <module>\n",
      "    import torch\n",
      "  File \"/Users/cuser/Documents/cybertraining/venv/lib/python3.12/site-packages/torch/__init__.py\", line 1477, in <module>\n",
      "    from .functional import *  # noqa: F403\n",
      "  File \"/Users/cuser/Documents/cybertraining/venv/lib/python3.12/site-packages/torch/functional.py\", line 9, in <module>\n",
      "    import torch.nn.functional as F\n",
      "  File \"/Users/cuser/Documents/cybertraining/venv/lib/python3.12/site-packages/torch/nn/__init__.py\", line 1, in <module>\n",
      "    from .modules import *  # noqa: F403\n",
      "  File \"/Users/cuser/Documents/cybertraining/venv/lib/python3.12/site-packages/torch/nn/modules/__init__.py\", line 35, in <module>\n",
      "    from .transformer import TransformerEncoder, TransformerDecoder, \\\n",
      "  File \"/Users/cuser/Documents/cybertraining/venv/lib/python3.12/site-packages/torch/nn/modules/transformer.py\", line 20, in <module>\n",
      "    device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "/Users/cuser/Documents/cybertraining/venv/lib/python3.12/site-packages/torch/nn/modules/transformer.py:20: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_numpy.cpp:84.)\n",
      "  device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8af4f85b-3822-4288-9566-0f0ac0cfa053",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../dataset/chattahoochee_3hr_02336490.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fc9eb646-4308-449c-84c0-00cd1de182c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0600e784-ec1c-4ab8-ab6b-9b765b4dee83",
   "metadata": {},
   "source": [
    "Here we define **RiverData** a custom Dataset class to load the dataset we have. It extends the pytorch Dataset class.  \n",
    "- We need to define \\_\\_init__() function which can be used for loading data from file and optionally for data preprocessing.\n",
    "- Thereafter we define \\_\\_len__() function which gives the length of dataset.\n",
    "- Then we define \\_\\_getitem__() function which returns an instance of (feature, label) tuple which can be used for model training.\n",
    "  For our time series data, feature means the past values to be used for training and label means the future values to be predicted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "742b694d-9966-4fd3-bca7-51f398a8775f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RiverData(torch.utils.data.Dataset):\n",
    "    \n",
    "    def __init__(self, df, target, datecol, seq_len, pred_len):\n",
    "        self.df = df\n",
    "        self.datecol = datecol\n",
    "        self.target = target\n",
    "        self.seq_len = seq_len\n",
    "        self.pred_len = pred_len\n",
    "        self.setIndex()\n",
    "        \n",
    "\n",
    "    def setIndex(self):\n",
    "        self.df.set_index(self.datecol, inplace=True)\n",
    "    \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df) - self.seq_len - self.pred_len\n",
    "\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if len(self.df) <= (idx + self.seq_len+self.pred_len):\n",
    "            raise IndexError(f\"Index {idx} is out of bounds for dataset of size {len(self.df)}\")\n",
    "        df_piece = self.df[idx:idx+self.seq_len].values\n",
    "        feature = torch.tensor(df_piece, dtype=torch.float32)\n",
    "        label_piece = self.df[self.target][idx + self.seq_len:  idx+self.seq_len+self.pred_len].values\n",
    "        label = torch.tensor(label_piece, dtype=torch.float32)\n",
    "        return (feature, label) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60c24959-e72f-435d-8a14-69a648fa5ab1",
   "metadata": {},
   "source": [
    "### Normalize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "46d897d9-946e-4bbe-90a6-cc8d8a223c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(path)\n",
    "raw_df = df.drop('DATE', axis=1, inplace=False)\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Apply the transformations\n",
    "df_scaled = scaler.fit_transform(raw_df)\n",
    "\n",
    "df_scaled = pd.DataFrame(df_scaled, columns=raw_df.columns)\n",
    "df_scaled['DATE'] = df['DATE']\n",
    "df = df_scaled"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a4781c6-88ed-4b28-aa0e-f669bf7c75f5",
   "metadata": {},
   "source": [
    "Some advanced python syntax have been used here. \\\n",
    "*common_args : it's used to pass arguments to a function, where common_args represents a python list \\\n",
    "**common_args: it's used to pass arguments to a function, where common_args represents a python dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9e63a535-a817-4429-be17-f3e3a02e4f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_size = int(0.7 * len(df))\n",
    "test_size = int(0.2 * len(df))\n",
    "val_size = len(df) - train_size - test_size\n",
    "\n",
    "seq_len = 8\n",
    "pred_len = 1\n",
    "num_features = 7\n",
    "num_layers = 1\n",
    "\n",
    "\n",
    "common_args = ['gaze_height', 'DATE', seq_len, pred_len]\n",
    "train_dataset = RiverData(df[:train_size], *common_args)\n",
    "val_dataset = RiverData(df[train_size: train_size+val_size], *common_args)\n",
    "test_dataset = RiverData(df[train_size+val_size : len(df)], *common_args)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "501879b1-dd1c-4ff0-afb3-ff25a345df05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Important parameters\n",
    "\n",
    "BATCH_SIZE = 512 # keep as big as can be handled by GPU and memory\n",
    "SHUFFLE = False # we don't shuffle the time series data\n",
    "DATA_LOAD_WORKERS = 1 # it depends on amount of data you need to load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ae359aec-9435-4229-8587-5f120b0370b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "common_args = {'batch_size': BATCH_SIZE, 'shuffle': SHUFFLE}\n",
    "train_loader = DataLoader(train_dataset, **common_args)\n",
    "val_loader = DataLoader(val_dataset, **common_args)\n",
    "test_loader = DataLoader(test_dataset, **common_args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc7ac35c-8ecc-4ab7-a97c-0cb4d59bc624",
   "metadata": {},
   "source": [
    "### Here we define our pytorch model.\n",
    "\n",
    "BasicTransformerNetwork is the model class, it extends the Module class provided by pytorch. \\\n",
    "- We define \\_\\_init__() function. It sets up layers and defines the model parameters.\n",
    "- Also, we define forward() function which defines how the forwared pass computation occurs\n",
    "- We also implement PositionalEncoding class which is an important part of transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "01cd8d0d-2058-4dfe-9046-78cde5fd2f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The transformer implementation in pytorch doesn't implement the \n",
    "# positional encoding which is an essential part of the transforemer model\n",
    "\n",
    "# Provide more description of positional encoding\n",
    "class PositionalEncoding(torch.nn.Module):\n",
    "    def __init__(self, d_model, dropout=0.1, max_len=5000):\n",
    "        super().__init__();\n",
    "        self.dropout = torch.nn.Dropout(p=dropout)\n",
    "\n",
    "        Xp = torch.zeros(max_len, d_model) # max_len x d_model\n",
    "        position = torch.arange(0, max_len).unsqueeze(1) # max_len x 1\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2) * (-math.log(100000.0) / d_model)) #length: d_model/2\n",
    "\n",
    "        #Applying sine to even indices in the array; 2i\n",
    "        Xp[:, 0::2] = torch.sin(position.float() * div_term)\n",
    "\n",
    "        #Applying cosine to odd indices in the array; 2i + 1\n",
    "        Xp[:, 1::2] = torch.cos(position.float() * div_term)\n",
    "\n",
    "        Xp = Xp.unsqueeze(1)\n",
    "        self.register_buffer('Xp', Xp)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x  = x + self.Xp[:x.size(0)]\n",
    "        return self.dropout(x)\n",
    "\n",
    "\n",
    "class BasicTransformerNetwork(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self, seq_len, pred_len):\n",
    "        # call the constructor of the base class\n",
    "        super().__init__()\n",
    "        self.model_type = 'Transformer'\n",
    "        self.seq_len = seq_len\n",
    "        self.pred_len = pred_len\n",
    "        self.num_features = num_features\n",
    "\n",
    "        # I don't think the embedding size should be this big. We will see.\n",
    "        self.embedding_size = 128 #The features are converted to 512 embeddings\n",
    "        self.num_layers = num_layers\n",
    "        self.pos_encoder = PositionalEncoding(self.embedding_size, 0.1, 10000)\n",
    "        \n",
    "        \n",
    "        self.encLayer = torch.nn.TransformerEncoderLayer(d_model=self.embedding_size, nhead=8, \n",
    "                                                 dim_feedforward=256, dropout=0.1, activation=\"relu\", \n",
    "                                                 layer_norm_eps=1e-05, batch_first=True, norm_first=False, bias=True, \n",
    "                                                 device=None, dtype=None)\n",
    "        \n",
    "        self.transformerEnc = torch.nn.TransformerEncoder(self.encLayer, num_layers=self.num_layers)\n",
    "\n",
    "        self.input_fc = torch.nn.Linear(self.num_features, self.embedding_size)\n",
    "        self.relu = torch.nn.ReLU()\n",
    "        \n",
    "        self.output_fc1 = torch.nn.Linear(self.embedding_size, self.pred_len)\n",
    "        self.output_fc2 = torch.nn.Linear(self.seq_len, 1)\n",
    "\n",
    "        \n",
    "\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.input_fc(x) * np.sqrt(self.embedding_size)\n",
    "        x = self.pos_encoder(x)\n",
    "        out = self.transformerEnc(x)\n",
    "        out = self.output_fc1(out) # dimension 512 x seq_len x pred_len\n",
    "        out = out.transpose(1,2) # dimension 512 x pred_len x seq_len\n",
    "        out = self.output_fc2(out) # dimension 512 x pred_len x 1\n",
    "        out = out.squeeze(-1) # dimension 512 x pred_len\n",
    "        return out\n",
    "# Note that the gradients are stored insize the FC layer objects\n",
    "# For each training example we need to get rid of these gradients"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f579dc18-584e-414b-ae8e-37f62e4b42f3",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b600c877-3409-48f9-80e5-3fdde7731817",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2.2\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5277794b-fe37-4595-8554-d26db5710e44",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BasicTransformerNetwork(seq_len, pred_len)\n",
    "loss = torch.nn.MSELoss()\n",
    "learning_rate = 2e-2\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr = learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1afde643-9953-4129-8415-7b4836c31300",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([384, 128])\n",
      "torch.Size([384])\n",
      "torch.Size([128, 128])\n",
      "torch.Size([128])\n",
      "torch.Size([256, 128])\n",
      "torch.Size([256])\n",
      "torch.Size([128, 256])\n",
      "torch.Size([128])\n",
      "torch.Size([128])\n",
      "torch.Size([128])\n",
      "torch.Size([128])\n",
      "torch.Size([128])\n",
      "torch.Size([384, 128])\n",
      "torch.Size([384])\n",
      "torch.Size([128, 128])\n",
      "torch.Size([128])\n",
      "torch.Size([256, 128])\n",
      "torch.Size([256])\n",
      "torch.Size([128, 256])\n",
      "torch.Size([128])\n",
      "torch.Size([128])\n",
      "torch.Size([128])\n",
      "torch.Size([128])\n",
      "torch.Size([128])\n",
      "torch.Size([128, 7])\n",
      "torch.Size([128])\n",
      "torch.Size([1, 128])\n",
      "torch.Size([1])\n",
      "torch.Size([1, 8])\n",
      "torch.Size([1])\n"
     ]
    }
   ],
   "source": [
    "for gen in model.parameters():\n",
    "    print(gen.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4b3cc7a8-9844-4eae-a601-4787513eb1cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features shape:  torch.Size([512, 8, 7])\n",
      "labels shape:  torch.Size([512, 1])\n"
     ]
    }
   ],
   "source": [
    "for i, (f,l) in enumerate(train_loader):\n",
    "    print('features shape: ', f.shape)\n",
    "    print('labels shape: ', l.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "22683e91-642a-494b-abc5-069dc6fa9eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define metrics\n",
    "import numpy as np\n",
    "epsilon = np.finfo(float).eps\n",
    "\n",
    "def wape_function(y, y_pred):\n",
    "    \"\"\"Weighted Average Percentage Error metric in the interval [0; 100]\"\"\"\n",
    "    y = np.array(y)\n",
    "    y_pred = np.array(y_pred)\n",
    "    nominator = np.sum(np.abs(np.subtract(y, y_pred)))\n",
    "    denominator = np.add(np.sum(np.abs(y)), epsilon)\n",
    "    wape = np.divide(nominator, denominator) * 100.0\n",
    "    return wape\n",
    "\n",
    "def nse_function(y, y_pred):\n",
    "    y = np.array(y)\n",
    "    y_pred = np.array(y_pred)\n",
    "    return (1-(np.sum((y_pred-y)**2)/np.sum((y-np.mean(y))**2)))\n",
    "\n",
    "\n",
    "def evaluate_model(model, data_loader):\n",
    "    # following line prepares the model for evaulation mode. It disables dropout and batch normalization if they have \n",
    "    # are part of the model. For our simple model it's not necessary. Still I'm going to use it.\n",
    "\n",
    "    model.eval()\n",
    "    all_inputs = torch.empty((0, seq_len, num_features))\n",
    "    all_labels = torch.empty(0, pred_len)\n",
    "    for inputs, labels in data_loader:\n",
    "        all_inputs = torch.vstack((all_inputs, inputs))\n",
    "        all_labels = torch.vstack((all_labels, labels))\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(all_inputs)\n",
    "        nse = nse_function(all_labels.numpy(), outputs.numpy())\n",
    "        wape = wape_function(all_labels.numpy(), outputs.numpy())\n",
    "        \n",
    "    print(f'NSE : {nse}', end=' ')\n",
    "    print(f'WAPE : {wape}')\n",
    "    \n",
    "    model.train()\n",
    "    return nse, wape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9beaf3a1-2c40-4fc6-b0f7-c352b5763231",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: 0.39835770916322183 "
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Numpy is not available",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 20\u001b[0m\n\u001b[1;32m     17\u001b[0m     epoch_loss\u001b[38;5;241m.\u001b[39mappend(loss_val\u001b[38;5;241m.\u001b[39mitem())\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28msum\u001b[39m(epoch_loss)\u001b[38;5;241m/\u001b[39m\u001b[38;5;28mlen\u001b[39m(epoch_loss)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m, end\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 20\u001b[0m nse, wape \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[14], line 33\u001b[0m, in \u001b[0;36mevaluate_model\u001b[0;34m(model, data_loader)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m     32\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m model(all_inputs)\n\u001b[0;32m---> 33\u001b[0m     nse \u001b[38;5;241m=\u001b[39m nse_function(\u001b[43mall_labels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m, outputs\u001b[38;5;241m.\u001b[39mnumpy())\n\u001b[1;32m     34\u001b[0m     wape \u001b[38;5;241m=\u001b[39m wape_function(all_labels\u001b[38;5;241m.\u001b[39mnumpy(), outputs\u001b[38;5;241m.\u001b[39mnumpy())\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNSE : \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnse\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m, end\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Numpy is not available"
     ]
    }
   ],
   "source": [
    "num_epochs = 30\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    epoch_loss = []\n",
    "    for batch_idx, (inputs, labels) in enumerate(train_loader):\n",
    "        outputs = model(inputs)\n",
    "        loss_val = loss(outputs, labels)\n",
    "\n",
    "        # calculate gradients for back propagation\n",
    "        loss_val.backward()\n",
    "\n",
    "        # update the weights based on the gradients\n",
    "        optimizer.step()\n",
    "\n",
    "        # reset the gradients, avoid gradient accumulation\n",
    "        optimizer.zero_grad()\n",
    "        epoch_loss.append(loss_val.item())\n",
    "    \n",
    "    print(f'Epoch {epoch+1}: {sum(epoch_loss)/len(epoch_loss)}', end=' ')\n",
    "    nse, wape = evaluate_model(model, val_loader)\n",
    "    \n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f7216e93-a35d-4aa5-83db-2e43ea380f6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NSE : 0.8960729837417603 WAPE : 29.622249249767947\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(np.float32(0.896073), np.float64(29.622249249767947))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_model(model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "722fee71-de14-463f-abf6-e35f9f002ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the results with the metrics inside it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a2f592f-d2be-4ea2-9e9e-d034d45f551d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c474aced-89cf-41c7-ae2c-b98c4b87b1b9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
